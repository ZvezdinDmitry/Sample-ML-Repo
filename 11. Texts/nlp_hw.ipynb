{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8ff717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import multiprocessing\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af2742",
   "metadata": {},
   "source": [
    "Скачаем данные, посмотрим, содержат ли они пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b688007d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Hotel_name</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Park Hyatt</td>\n",
       "      <td>Refuge in Chennai</td>\n",
       "      <td>Excellent room and exercise facility. All arou...</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hilton Chennai</td>\n",
       "      <td>Hilton Chennai</td>\n",
       "      <td>Very comfortable and felt safe. \\r\\nStaff were...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Royal Regency</td>\n",
       "      <td>No worth the rating shown in websites. Pricing...</td>\n",
       "      <td>Not worth the rating shown. Service is not goo...</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>Good stay</td>\n",
       "      <td>First of all nice &amp; courteous staff, only one ...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Park Hyatt</td>\n",
       "      <td>Needs improvement</td>\n",
       "      <td>Overall ambience of the hotel is very good. In...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id         Hotel_name                                       Review_Title  \\\n",
       "0   0         Park Hyatt                                  Refuge in Chennai   \n",
       "1   1     Hilton Chennai                                     Hilton Chennai   \n",
       "2   2  The Royal Regency  No worth the rating shown in websites. Pricing...   \n",
       "3   3             Rivera                                          Good stay   \n",
       "4   4         Park Hyatt                                  Needs improvement   \n",
       "\n",
       "                                         Review_Text  Rating  \n",
       "0  Excellent room and exercise facility. All arou...    80.0  \n",
       "1  Very comfortable and felt safe. \\r\\nStaff were...   100.0  \n",
       "2  Not worth the rating shown. Service is not goo...    71.0  \n",
       "3  First of all nice & courteous staff, only one ...    86.0  \n",
       "4  Overall ambience of the hotel is very good. In...    86.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./nlp/train.csv\", encoding=\"cp1252\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0b4bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0.00000\n",
       "Hotel_name      0.00000\n",
       "Review_Title    0.09145\n",
       "Review_Text     0.00000\n",
       "Rating          0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f2606",
   "metadata": {},
   "source": [
    "Для начала просто воспользуемся CountVectorizer и обучим линейную регрессию с параметрами по-умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421e4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data.Review_Text\n",
    "X = CountVectorizer().fit_transform(texts)\n",
    "y = data.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddf9df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134.9622019299266\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "pred = linreg.predict(X)\n",
    "print((-np.mean(cross_val_score(LinearRegression(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2018ec95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.114002971450166"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25db56f",
   "metadata": {},
   "source": [
    "Видим, что результат крайне плачевный отклонение предсказанных значений от реальных в разы выше, чем стандартное отклонение, то есть среднее - более точное предсказание, чем результат модели.\n",
    "\n",
    "Попробуем исправить ситуацию, для начала уберем из текста все, что не является словами английского языка с помощью регулярных выражений, затем уберем стоп-слова и, наконец, воспользуемся стеммингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9249721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_san = texts.apply(lambda x: re.findall(r\"\\b[A-Za-z]+\\b\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17bcf00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "texts_reduced = texts_san.apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1cb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "texts_stemmed = texts_reduced.apply(lambda x: list(map(lambda y: stemmer.stem(y), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e11d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_final = texts_stemmed.str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7bb982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.90195678152136\n"
     ]
    }
   ],
   "source": [
    "X = CountVectorizer().fit_transform(texts_final)\n",
    "print((-np.mean(cross_val_score(LinearRegression(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f52faf",
   "metadata": {},
   "source": [
    "Ситуация стала хуже, попробуем не использовать стемминг, а остановится на выкидывании стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ee3cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.33542240176071\n"
     ]
    }
   ],
   "source": [
    "X = CountVectorizer().fit_transform(texts_reduced.str.join(\" \"))\n",
    "print((-np.mean(cross_val_score(LinearRegression(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832a9bc",
   "metadata": {},
   "source": [
    "Так уже лучше, остановимся на этом варианте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc8b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_final = texts_reduced.str.join(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5942b8",
   "metadata": {},
   "source": [
    "Попробуем воспользоваться более сложным способом векторизации: TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c48e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.496089315342655\n"
     ]
    }
   ],
   "source": [
    "X = TfidfVectorizer().fit_transform(texts_final)\n",
    "print((-np.mean(cross_val_score(LinearRegression(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94bdd1",
   "metadata": {},
   "source": [
    "Результат стал сильно лучше, попробуем перебрать число н-грамм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b903507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший RMSE: 14.183353697236678 достигнут на н-граммах: от 1 до 2.\n"
     ]
    }
   ],
   "source": [
    "best_score = np.inf\n",
    "best_ngrams = tuple()\n",
    "ngrams_list = [(j,i) for i in range(1, 7) for j in range(1, i+1)]\n",
    "for ngrams in ngrams_list:\n",
    "    X = TfidfVectorizer(ngram_range=ngrams).fit_transform(texts_final)\n",
    "    score = (-np.mean(cross_val_score(LinearRegression(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5\n",
    "    if best_score > score:\n",
    "        best_score = score\n",
    "        best_ngrams = ngrams\n",
    "print(f\"Наилучший RMSE: {best_score} достигнут на н-граммах: от {best_ngrams[0]} до {best_ngrams[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6785220",
   "metadata": {},
   "source": [
    "Стало еще лучше, попробуем использовать регрессю с L1 регуляризацией с параметрами по-умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4443b8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.114376226361674\n"
     ]
    }
   ],
   "source": [
    "X = TfidfVectorizer(ngram_range=(1, 2)).fit_transform(texts_final)\n",
    "print((-np.mean(cross_val_score(Lasso(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ca6e9",
   "metadata": {},
   "source": [
    "Стало хуже, попробуем перебрать коэффициент регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a939106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший RMSE: 20.04065699882025 достигнут с коэффициентом: 0.1.\n"
     ]
    }
   ],
   "source": [
    "best_score = np.inf\n",
    "best_ngrams = 0\n",
    "alphas = np.concatenate((np.arange(0.1, 1.7, 0.2), np.arange(2, 10, 1)))\n",
    "for alpha in alphas:\n",
    "    score = (-np.mean(cross_val_score(Lasso(alpha=alpha), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5\n",
    "    if best_score > score:\n",
    "        best_score = score\n",
    "        best_alpha = alpha\n",
    "print(f\"Наилучший RMSE: {best_score} достигнут с коэффициентом: {best_alpha}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891109fe",
   "metadata": {},
   "source": [
    "Видно, что регуляризация не помогла улучшить результат, попробуем аналогичную процедуру для L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1da5905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.719073660324904\n"
     ]
    }
   ],
   "source": [
    "print((-np.mean(cross_val_score(Ridge(), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63affc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший RMSE: 13.910197342475541 достигнут с коэффициентом: 0.1.\n"
     ]
    }
   ],
   "source": [
    "best_score = np.inf\n",
    "best_ngrams = 0\n",
    "alphas = np.concatenate((np.arange(0.1, 1.7, 0.2), np.arange(2, 10, 1)))\n",
    "for alpha in alphas:\n",
    "    score = (-np.mean(cross_val_score(Ridge(alpha=alpha), X, y, scoring=\"neg_mean_squared_error\", cv=5)))**0.5\n",
    "    if best_score > score:\n",
    "        best_score = score\n",
    "        best_alpha = alpha\n",
    "print(f\"Наилучший RMSE: {best_score} достигнут с коэффициентом: {best_alpha}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b626c7",
   "metadata": {},
   "source": [
    "Ridge регрессия справилась лучше, результат чуть лучше, чем у простой линейной регрессии.\n",
    "\n",
    "Попробуем более сложную модель - градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6a6e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.516067831884133\n"
     ]
    }
   ],
   "source": [
    "boost = CatBoostRegressor(iterations=300, loss_function=\"RMSE\", verbose=False, task_type=\"GPU\")\n",
    "print((-np.mean(cross_val_score(boost, X, y, scoring=\"neg_mean_squared_error\", cv=3))) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a98d9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.152900396322352\n"
     ]
    }
   ],
   "source": [
    "boost = CatBoostRegressor(loss_function=\"RMSE\", random_state=42, depth=7, iterations=200, learning_rate=0.2, verbose=False)\n",
    "print((-np.mean(cross_val_score(boost, X, y, scoring=\"neg_mean_squared_error\", cv=3))) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338889c7",
   "metadata": {},
   "source": [
    "Путем ручного перебора параметров (в связи с ОЧЕНЬ большим временем работы GridSearch) удалось немного повысить качество, однако оно хуже, чем у Ridge регрессии.\n",
    "\n",
    "Попробуем случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a63a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.201563564853476\n"
     ]
    }
   ],
   "source": [
    "workers = multiprocessing.cpu_count() - 1\n",
    "forest = RandomForestRegressor(n_jobs=workers)\n",
    "print((-np.mean(cross_val_score(forest, X, y, scoring=\"neg_mean_squared_error\", cv=3))) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72497e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 0.2,\n",
       " 'max_samples': None,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor(random_state=42, n_jobs=workers)\n",
    "parameters = {\"n_estimators\": [100, 200], \"max_depth\": [5, 10, 20], \"max_features\": [0.2, 0.333, \"sqrt\", \"auto\"], \"max_samples\": [0.1, 0.2, 0.5, None]}\n",
    "gs_forest = GridSearchCV(forest, param_grid=parameters, scoring=\"neg_mean_squared_error\", cv=3)\n",
    "gs_forest.fit(X, y)\n",
    "gs_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8838ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.644247254387942\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestRegressor(max_depth=20, max_features=0.2, max_samples=None,\n",
    "                               n_estimators=200, random_state=42, n_jobs=workers)\n",
    "print((-np.mean(cross_val_score(forest, X, y, scoring=\"neg_mean_squared_error\", cv=5))) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234fa280",
   "metadata": {},
   "source": [
    "При подборе параметров, стало хуже, лес с параметрвами по-умолчанию справляется хуже регресси.\n",
    "\n",
    "Таким образом наилучшая модель - Ridge регрессия с коэффициентом регуляризации 0.1.\n",
    "\n",
    "Получим с ее помощью предсказания для тестового набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0915084",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"./nlp/test.csv\", encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fea28d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0.000000\n",
       "Hotel_name      0.000000\n",
       "Review_Title    0.088861\n",
       "Review_Text     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.isna().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4ba5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_test.Review_Text\n",
    "test_san = test.apply(lambda x: re.findall(r\"\\b[A-Za-z]+\\b\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82b853f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "test_reduced = test_san.apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b49aa260",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =  TfidfVectorizer(ngram_range=(1, 2)).fit(texts_final)\n",
    "X = vectorizer.transform(texts_final)\n",
    "X_test = vectorizer.transform(test_reduced.str.join(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cc87714",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X, y)\n",
    "prediction = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aca96c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Id\": data_test.Id, \"Rating\": prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7eabd620",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8e8ba4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a0ef7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгенерируем набор данных\n",
    "n_objects = 100000\n",
    "n_features = 500\n",
    "np.random.seed(42)\n",
    "sgd_steps = 100000\n",
    "gd_steps = 1000\n",
    "\n",
    "weights_true = np.random.normal(size=n_features)\n",
    "X = np.random.uniform(-50, 50, (n_objects, n_features))\n",
    "Y = np.dot(X, weights_true) + np.random.normal(0, 1, n_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ef540",
   "metadata": {},
   "source": [
    "## Ridge с градиентным спуском \n",
    "Работает на уровне с моделью из scikitlearn (отличие на уровне 5 знака после запятой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "915e874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeReg(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_steps, learning_rate=0.01, lambda_parameter=1):\n",
    "        self.n_steps = n_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_parameter = lambda_parameter\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        np.random.seed(42)\n",
    "        weights = np.random.uniform(-1, 1, X.shape[1])\n",
    "        for step in range(self.n_steps):\n",
    "            learning_rate = self.learning_rate\n",
    "            weights -= -2 * learning_rate * ((X.T.dot(Y - np.dot(X, weights)) / Y.size) - \n",
    "                                             (self.lambda_parameter * weights / weights.size))\n",
    "        self.weights = weights\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9c1a49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bdbb0533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 моей модели: 0.9999837497180591\n",
      "R^2 модели из sklearn: 0.9999975142503074\n"
     ]
    }
   ],
   "source": [
    "Ridge_my = RidgeReg(n_steps=gd_steps).fit(X_train, Y_train)\n",
    "prediction = Ridge_my.predict(X_test)\n",
    "r2 = r2_score(Y_test, prediction)\n",
    "sk_Ridge = Ridge().fit(X=X_train, y=Y_train)\n",
    "sk_prediction = sk_Ridge.predict(X_test)\n",
    "sk_r2 = r2_score(Y_test, sk_prediction)\n",
    "\n",
    "print(\"R^2 моей модели:\", r2)\n",
    "print(\"R^2 модели из sklearn:\", sk_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f3921",
   "metadata": {},
   "source": [
    "## Модель со стохастическим градиентным спуском\n",
    "Работает хуже модели из scikitlearn (отличие на уровне сотых долей), зато работает быстрее модели с классическим градиентным спуском."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "009ce5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegSGD(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_steps, batch_size=20, learning_rate=0.1, lambda_parameter=1):\n",
    "        self.n_steps = n_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_parameter = lambda_parameter\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        np.random.seed(42)\n",
    "        weights = np.random.uniform(-1, 1, X.shape[1])\n",
    "        for step in range(self.n_steps):\n",
    "            learning_rate = self.learning_rate\n",
    "            learning_rate *= 1 / (step + 1)\n",
    "            n_objects = X.shape[0]\n",
    "            ind = np.random.randint(0, n_objects, self.batch_size)\n",
    "            weights -= -2 * learning_rate * ((X[ind].T.dot(Y[ind] - np.dot(X[ind], weights)) / Y[ind].size) - \n",
    "                                             (self.lambda_parameter * weights / weights.size))\n",
    "        self.weights = weights\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "611d5778",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4ec604c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 моей модели: 0.9680646428370597\n",
      "R^2 модели из sklearn: 0.9999974837265182\n"
     ]
    }
   ],
   "source": [
    "Ridge_my = RidgeRegSGD(n_steps=sgd_steps).fit(X_train, Y_train)\n",
    "prediction = Ridge_my.predict(X_test)\n",
    "r2 = r2_score(Y_test, prediction)\n",
    "\n",
    "sk_Ridge = Ridge().fit(X=X_train, y=Y_train)\n",
    "sk_prediction = sk_Ridge.predict(X_test)\n",
    "sk_r2 = r2_score(Y_test, sk_prediction)\n",
    "print(\"R^2 моей модели:\", r2)\n",
    "print(\"R^2 модели из sklearn:\", sk_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9ed31",
   "metadata": {},
   "source": [
    "## Логистическая регрессия "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2dc3dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_steps, learning_rate=0.01):\n",
    "        self.n_steps = n_steps\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(vec):\n",
    "        return 1 / (1 + np.exp(-vec))\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        np.random.seed(42)\n",
    "        weights = np.random.uniform(-1, 1, X.shape[1])\n",
    "        for step in range(self.n_steps):\n",
    "            learning_rate = self.learning_rate\n",
    "            weights -= learning_rate * X.T.dot((self.sigmoid(np.dot(X, weights)) - Y)) / Y.size\n",
    "        self.weights = weights\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array(self.sigmoid(np.dot(X, self.weights)) > 0.5, dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0dc5c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузим данные из датасета Ирис\n",
    "X, y = load_iris(return_X_y=True)\n",
    "y = y[y != 2]\n",
    "X = X[:100]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e8a66103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d0a7f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score моей модели: 1.0\n",
      "accuracy score модели из sklearn: 1.0\n"
     ]
    }
   ],
   "source": [
    "logreg = LogReg(n_steps=1000).fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "accuracy_score(prediction, y_test)\n",
    "sk_logreg = LogisticRegression().fit(X_train, y_train)\n",
    "sk_prediction = sk_logreg.predict(X_test)\n",
    "accuracy_score(sk_prediction, y_test)\n",
    "print(\"accuracy score моей модели:\", accuracy_score(prediction, y_test))\n",
    "print(\"accuracy score модели из sklearn:\", accuracy_score(sk_prediction, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
